{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "In recent years, Cloud Model 1 (CM1; http://www2.mmm.ucar.edu/people/bryan/cm1/) has become a very popular tool for performing idealized studies of atmospheric phenomena. There exists very little support for computing trajectories using CM1 output, which are usually necessary to understand the processes of the atmospheric phenomena of interest. Natively, CM1 only supports 'online' forward trajectories in 2D simulations and in 3D simulation without terrain. I wrote this script because there are no adequate tools available to compute highly customizable 'offline' trajectories in simulations with terrain. This script is intended to be easily customizable.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Can compute backward or forward trajectories (Default is backward, but can be forward with simple changes to \"Calculate Trajectories\" block)\n",
    "* Written to work with 3D model output (can be modified to work with 2D output)\n",
    "* Will work with or without terrain\n",
    "* Initial location, number, and density of parcels can be easily specified in \"Initialize Parcels\" block\n",
    "* Uses xarray and Dask to distribute memory and calculation across multiple processors\n",
    "* With modifications, can be used with WRF output (several others have already done so)\n",
    "* Comments that say \"set by user\" are specific to model output and desired trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import interpolate\n",
    "import time\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CM1 Output\n",
    "\n",
    "* User must insert path to data\n",
    "    * If model output is one file use ***xr.open_dataset***\n",
    "    * If model output is in multiple files use ***xr.openmfdataset***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use xarray to open model output and specify chunking if data set is large (set by user)\n",
    "ds = xr.open_dataset('/uufs/chpc.utah.edu/common/home/steenburgh-group8/tom/cm1/output/15ms_1500m_tug.nc', chunks={'nk': 1})\n",
    "\n",
    "#Get model output dimensions\n",
    "num_x = ds.nx #Number of gridpoints in x\n",
    "num_y = ds.ny #Number of gridpoints in y\n",
    "num_z = ds.nz #Number of gridpoints in z\n",
    "\n",
    "x = np.arange(0,num_x,1)\n",
    "y = np.arange(0,num_y,1)\n",
    "z = np.arange(0,num_z,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39711\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>10</li>\n",
       "  <li><b>Cores: </b>40</li>\n",
       "  <li><b>Memory: </b>96.49 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:39711' processes=10 cores=40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Option to use multiple processors and threads (set by user)\n",
    "from dask.distributed import Client, LocalCluster\n",
    "c = LocalCluster(n_workers=10, threads_per_worker=4)\n",
    "client = Client(c)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User must enter desired trajectory characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of parcels in vertical (can be more than number of vertical levels; set by user) \n",
    "num_seeds_z = 1\n",
    "\n",
    "#Number of parcels in y (set by user) \n",
    "num_seeds_y = 50\n",
    "\n",
    "#Number of time steps to run trajectories back (set by user) \n",
    "time_steps = 150\n",
    "\n",
    "#Time step to start backward trajectories at (set by user) \n",
    "start_time_step = 240\n",
    "\n",
    "#Variable to record at each parcel's location throughout trajectory (code can be easily modified to add more; set by user) \n",
    "var_name1 = 'th'\n",
    "\n",
    "#Set as 'Y' or 'N' for 'yes' or 'no' if the u, v, and w model output is on the staggered grid \n",
    "#(unless you have interpolated u, v, and w to the scalar grid, they are most likely on the staggered grid (set by user)\n",
    "staggered = 'N'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model output info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horizontal resolution of model output (meters)\n",
    "hor_resolution = (ds.xf[1].values-ds.xf[0].values)*1000\n",
    "\n",
    "#Vertical resolution of model output (meters). Changes in x and y, if there is terrain, and z, if grid is stretched.\n",
    "vert_resolution = ds.zh[0,1:,:,:].values-ds.zh[0,:-1,:,:].values \n",
    "                  \n",
    "#Model output time step length (seconds)\n",
    "time_step_length = (ds.time[1].values - ds.time[0].values)/np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create empty arrays to store x, y, and z positions of parcels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpos = np.zeros((time_steps, num_seeds_z, num_seeds_y)) #x-location (grid points on staggered grid)\n",
    "ypos = np.zeros((time_steps, num_seeds_z, num_seeds_y)) #y-location (grid points on staggered grid)\n",
    "zpos = np.zeros((time_steps, num_seeds_z, num_seeds_y)) #z-location (grid points on staggered grid)\n",
    "zpos_heightASL = np.zeros((time_steps, num_seeds_z, num_seeds_y)) #Height above sea level (meters)\n",
    "zpos_vert_res = np.zeros((time_steps, num_seeds_z, num_seeds_y)) #Vertical grid spacing at parcel location (meters)\n",
    "variable1 = np.zeros((time_steps, num_seeds_z, num_seeds_y)) #User specified variable to track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial location of parcels in gridpoints, specifically on the staggered grid (set by user). Initializes an array of parcels in the the y-z domain (modification necessary for x-dimension or 3D array of parcels)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x-position\n",
    "xpos[0,:,:] = 2900 #This example initializes all seeds at same x-position (1000th x-grpt, set by user)\n",
    "\n",
    "#y-position   \n",
    "for i in range(num_seeds_y):\n",
    "    ypos[0,:,i] = 350+(4*i) #This example initializes seeds evenly in y-dimension (0th, 4th, 8th, etc. y-grpt; set by user)\n",
    "\n",
    "#z-position\n",
    "for i in range(num_seeds_z):\n",
    "    zpos[0,i,:] = 2 #This example initializes seeds evenly starting in z-dimension (0th, 1st, 2nd, etc., z-grpt; set by user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Initial Height of Parcels Above Sea Level\n",
    "Use the height of the models levels (meters above sea level) to convert from terrain following grid points to height above seal level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get height of vertical coordinates (scalar grid)\n",
    "zh = ds.zh[0,:,:,:].values\n",
    "\n",
    "#Create list of initial coordinates to get height (must subtract 0.5 grdpt from each location because zh is on scalar grid)\n",
    "xloc = (xpos[0,:,:]-0.5).flatten()\n",
    "yloc = (ypos[0,:,:]-0.5).flatten()\n",
    "zloc = (zpos[0,:,:]-0.5).flatten()\n",
    "coord_height = []\n",
    "for i in range(len(xloc)):\n",
    "    coord_height.append((zloc[i], yloc[i], xloc[i]))\n",
    "\n",
    "#Get the actual inital height of the parcels in meters above sea level\n",
    "zpos_heightASL[0,:,:] = np.reshape(interpolate.interpn((z,y,x), zh, coord_height, method='linear', bounds_error=False, fill_value= 0), (num_seeds_z, num_seeds_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Trajectories\n",
    "Unless user is changing trajectories from backwards to forwards, nothing should be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integration 0 took 13.92 seconds\n",
      "Integration 1 took 14.03 seconds\n",
      "Integration 2 took 13.74 seconds\n",
      "Integration 3 took 14.84 seconds\n",
      "Integration 4 took 13.90 seconds\n",
      "Integration 5 took 13.40 seconds\n",
      "Integration 6 took 14.17 seconds\n",
      "Integration 7 took 14.14 seconds\n",
      "Integration 8 took 14.81 seconds\n",
      "Integration 9 took 15.04 seconds\n",
      "Integration 10 took 14.57 seconds\n",
      "Integration 11 took 14.24 seconds\n",
      "Integration 12 took 14.48 seconds\n",
      "Integration 13 took 13.82 seconds\n",
      "Integration 14 took 13.48 seconds\n",
      "Integration 15 took 13.82 seconds\n",
      "Integration 16 took 13.47 seconds\n",
      "Integration 17 took 13.62 seconds\n",
      "Integration 18 took 14.19 seconds\n",
      "Integration 19 took 13.66 seconds\n",
      "Integration 20 took 14.49 seconds\n",
      "Integration 21 took 14.04 seconds\n",
      "Integration 22 took 14.76 seconds\n",
      "Integration 23 took 13.87 seconds\n",
      "Integration 24 took 13.91 seconds\n",
      "Integration 25 took 14.08 seconds\n",
      "Integration 26 took 14.36 seconds\n",
      "Integration 27 took 14.70 seconds\n",
      "Integration 28 took 13.62 seconds\n",
      "Integration 29 took 13.75 seconds\n",
      "Integration 30 took 13.88 seconds\n",
      "Integration 31 took 13.52 seconds\n",
      "Integration 32 took 13.13 seconds\n",
      "Integration 33 took 13.44 seconds\n",
      "Integration 34 took 13.87 seconds\n",
      "Integration 35 took 13.33 seconds\n",
      "Integration 36 took 14.64 seconds\n",
      "Integration 37 took 13.20 seconds\n",
      "Integration 38 took 13.76 seconds\n",
      "Integration 39 took 12.82 seconds\n",
      "Integration 40 took 13.31 seconds\n",
      "Integration 41 took 13.52 seconds\n",
      "Integration 42 took 13.39 seconds\n",
      "Integration 43 took 13.52 seconds\n",
      "Integration 44 took 13.93 seconds\n",
      "Integration 45 took 13.58 seconds\n",
      "Integration 46 took 13.42 seconds\n",
      "Integration 47 took 13.85 seconds\n",
      "Integration 48 took 13.86 seconds\n",
      "Integration 49 took 15.53 seconds\n",
      "Integration 50 took 14.38 seconds\n",
      "Integration 51 took 15.56 seconds\n",
      "Integration 52 took 14.08 seconds\n",
      "Integration 53 took 13.02 seconds\n",
      "Integration 54 took 14.62 seconds\n",
      "Integration 55 took 14.43 seconds\n",
      "Integration 56 took 14.39 seconds\n",
      "Integration 57 took 14.24 seconds\n",
      "Integration 58 took 13.74 seconds\n",
      "Integration 59 took 14.59 seconds\n",
      "Integration 60 took 13.89 seconds\n",
      "Integration 61 took 13.39 seconds\n",
      "Integration 62 took 13.70 seconds\n",
      "Integration 63 took 13.85 seconds\n",
      "Integration 64 took 13.57 seconds\n",
      "Integration 65 took 14.37 seconds\n",
      "Integration 66 took 14.01 seconds\n",
      "Integration 67 took 14.71 seconds\n",
      "Integration 68 took 12.64 seconds\n",
      "Integration 69 took 15.02 seconds\n",
      "Integration 70 took 13.69 seconds\n",
      "Integration 71 took 13.98 seconds\n",
      "Integration 72 took 14.61 seconds\n",
      "Integration 73 took 13.95 seconds\n",
      "Integration 74 took 14.28 seconds\n",
      "Integration 75 took 14.79 seconds\n",
      "Integration 76 took 13.34 seconds\n",
      "Integration 77 took 13.98 seconds\n",
      "Integration 78 took 13.86 seconds\n",
      "Integration 79 took 14.10 seconds\n",
      "Integration 80 took 13.20 seconds\n",
      "Integration 81 took 14.91 seconds\n",
      "Integration 82 took 13.61 seconds\n",
      "Integration 83 took 13.51 seconds\n",
      "Integration 84 took 13.46 seconds\n",
      "Integration 85 took 14.26 seconds\n",
      "Integration 86 took 14.04 seconds\n",
      "Integration 87 took 13.71 seconds\n",
      "Integration 88 took 13.12 seconds\n",
      "Integration 89 took 13.90 seconds\n",
      "Integration 90 took 14.72 seconds\n",
      "Integration 91 took 13.80 seconds\n",
      "Integration 92 took 14.03 seconds\n",
      "Integration 93 took 13.40 seconds\n",
      "Integration 94 took 14.71 seconds\n",
      "Integration 95 took 14.46 seconds\n",
      "Integration 96 took 14.41 seconds\n",
      "Integration 97 took 14.38 seconds\n",
      "Integration 98 took 14.99 seconds\n",
      "Integration 99 took 14.33 seconds\n",
      "Integration 100 took 14.31 seconds\n",
      "Integration 101 took 15.39 seconds\n",
      "Integration 102 took 13.63 seconds\n",
      "Integration 103 took 14.22 seconds\n",
      "Integration 104 took 13.83 seconds\n",
      "Integration 105 took 13.81 seconds\n",
      "Integration 106 took 15.30 seconds\n",
      "Integration 107 took 13.80 seconds\n",
      "Integration 108 took 13.34 seconds\n",
      "Integration 109 took 13.69 seconds\n",
      "Integration 110 took 13.63 seconds\n",
      "Integration 111 took 14.05 seconds\n",
      "Integration 112 took 13.30 seconds\n",
      "Integration 113 took 14.41 seconds\n",
      "Integration 114 took 13.72 seconds\n",
      "Integration 115 took 14.10 seconds\n",
      "Integration 116 took 13.62 seconds\n",
      "Integration 117 took 13.58 seconds\n",
      "Integration 118 took 14.28 seconds\n",
      "Integration 119 took 14.36 seconds\n",
      "Integration 120 took 14.55 seconds\n",
      "Integration 121 took 14.48 seconds\n",
      "Integration 122 took 13.89 seconds\n",
      "Integration 123 took 13.47 seconds\n",
      "Integration 124 took 13.81 seconds\n",
      "Integration 125 took 14.66 seconds\n",
      "Integration 126 took 14.51 seconds\n",
      "Integration 127 took 13.76 seconds\n",
      "Integration 128 took 14.74 seconds\n",
      "Integration 129 took 14.14 seconds\n",
      "Integration 130 took 14.18 seconds\n",
      "Integration 131 took 13.79 seconds\n",
      "Integration 132 took 13.58 seconds\n",
      "Integration 133 took 14.44 seconds\n",
      "Integration 134 took 14.12 seconds\n",
      "Integration 135 took 14.13 seconds\n",
      "Integration 136 took 13.88 seconds\n",
      "Integration 137 took 13.05 seconds\n",
      "Integration 138 took 14.41 seconds\n",
      "Integration 139 took 13.72 seconds\n",
      "Integration 140 took 14.31 seconds\n",
      "Integration 141 took 13.49 seconds\n",
      "Integration 142 took 13.94 seconds\n",
      "Integration 143 took 13.25 seconds\n",
      "Integration 144 took 13.59 seconds\n",
      "Integration 145 took 14.81 seconds\n",
      "Integration 146 took 14.79 seconds\n",
      "Integration 147 took 13.63 seconds\n",
      "Integration 148 took 13.97 seconds\n"
     ]
    }
   ],
   "source": [
    "#Loop over all time steps and compute trajectory\n",
    "for t in range(time_steps-1):\n",
    "    \n",
    "    start = time.time() #Timer\n",
    "    \n",
    "    #Get model data\n",
    "    u = ds.uinterp[start_time_step-t,:,:,:].values\n",
    "    v = ds.vinterp[start_time_step-t,:,:,:].values\n",
    "    w = ds.winterp[start_time_step-t,:,:,:].values\n",
    "    var1 = getattr(ds,var_name1)[start_time_step-t,:,:,:].values\n",
    "        \n",
    "    #Get surface height grid (set to zero if no terrain)\n",
    "    try:\n",
    "        zs = np.array(ds.zs[0,:,:])\n",
    "    except:\n",
    "        zs = np.zeros((ds.ny, ds.nx))  \n",
    "        \n",
    "        \n",
    "    ############## Generate coordinates for interpolations ###############\n",
    "\n",
    "    #x, y, and z on staggered and scalar grids\n",
    "    xloc = np.copy(xpos[t,:,:]-0.5).flatten()\n",
    "    xloc_stag = np.copy(xpos[t,:,:]).flatten()\n",
    "    yloc = np.copy(ypos[t,:,:]-0.5).flatten()\n",
    "    yloc_stag = np.copy(ypos[t,:,:]).flatten()\n",
    "    zloc = np.copy(zpos[t,:,:]-0.5).flatten()\n",
    "    zloc_stag = np.copy(zpos[t,:,:]).flatten()\n",
    "\n",
    "    #If u, v, and w are staggered, generate three staggered sets of coordinates:\n",
    "    #    1) u-grid (staggered in x)\n",
    "    #    2) v-grid (staggered in y)\n",
    "    #    3) w-grid (staggered in z)\n",
    "    \n",
    "    if staggered == 'Y':\n",
    "        coord_u = []\n",
    "        coord_v = []\n",
    "        coord_w = []\n",
    "        for i in range(len(xloc)):\n",
    "            coord_u.append((zloc[i], yloc[i], xloc_stag[i])) \n",
    "            coord_v.append((zloc[i], yloc_stag[i], xloc[i])) \n",
    "            coord_w.append((zloc_stag[i], yloc[i], xloc[i])) \n",
    "    \n",
    "    #If not, generate scalar coordinates\n",
    "    else: \n",
    "        coord_u = []\n",
    "        coord_v = []\n",
    "        coord_w = []\n",
    "        for i in range(len(xloc)):\n",
    "            coord_u.append((zloc[i], yloc[i], xloc[i])) \n",
    "            coord_v.append((zloc[i], yloc[i], xloc[i])) \n",
    "            coord_w.append((zloc[i], yloc[i], xloc[i])) \n",
    "    \n",
    "    #Scalar coordinates for all other variables\n",
    "    coord = []\n",
    "    for i in range(len(xloc)):\n",
    "        coord.append((zloc[i], yloc[i], xloc[i])) \n",
    "    \n",
    "    ##########################################################################################################   \n",
    "    ########################## Integrate to determine parcel's new location ##################################\n",
    "    ##########################################################################################################   \n",
    "\n",
    "    \n",
    "    #########################   Calc new xpos in grdpts above surface  #######################################\n",
    "    xpos[t+1,:,:] = xpos[t,:,:] - np.reshape(interpolate.interpn((z,y,x), u, coord_u, method='linear', bounds_error=False, fill_value=np.nan)*time_step_length/hor_resolution, (num_seeds_z, num_seeds_y))\n",
    "\n",
    "    #########################   Calc new ypos in grdpts above surface  #######################################\n",
    "    ypos[t+1,:,:]  = ypos[t,:,:] - np.reshape(interpolate.interpn((z,y,x), v, coord_v, method='linear', bounds_error=False, fill_value=np.nan)*time_step_length/hor_resolution, (num_seeds_z, num_seeds_y))\n",
    "\n",
    "    #########################   Calc new zpos in meters above sea level ######################################\n",
    "    zpos_heightASL[t+1,:,:]  = zpos_heightASL[t,:,:] - np.reshape(interpolate.interpn((z,y,x), w, coord_w, method='linear', bounds_error=False, fill_value= 0)*time_step_length, (num_seeds_z, num_seeds_y))\n",
    "\n",
    "    ############# Convert zpos from meters above sea level to gridpts abve surface for interpolation #########\n",
    "    #Get vertical grid spacing at each parcel's location\n",
    "    zpos_vert_res[t,:,:] = np.reshape(interpolate.interpn((z[:-1],y,x), vert_resolution, coord, method='linear', bounds_error=False, fill_value= np.nan), (num_seeds_z, num_seeds_y))\n",
    "\n",
    "    #Get surface height at each parcel's location (scalar)\n",
    "    xloc = np.copy(xpos[t+1,:,:]-0.5).flatten()\n",
    "    yloc = np.copy(ypos[t+1,:,:]-0.5).flatten()\n",
    "    coord_zs = []\n",
    "    for i in range(len(xloc)):\n",
    "        coord_zs.append((yloc[i], xloc[i]))\n",
    "    surface_height = np.reshape(interpolate.interpn((y,x), zs, coord_zs, method='linear', bounds_error=False, fill_value= np.nan), (num_seeds_z, num_seeds_y))\n",
    "    \n",
    "    #Calculate zpos in grdpts above surface\n",
    "    zpos[t+1,:,:] = np.reshape((zpos_heightASL[t+1,:,:].flatten()-surface_height.flatten())/zpos_vert_res[t,:,:].flatten(), (num_seeds_z, num_seeds_y))\n",
    "    \n",
    "    ##########################################################################################################\n",
    "    \n",
    "    \n",
    "    #Prevent parcels from going into the ground\n",
    "    if staggered == 'Y':\n",
    "        zpos = zpos.clip(min=0.5)\n",
    "    else:\n",
    "        zpos = zpos.clip(min=0)\n",
    "    \n",
    "    #Calculate value of variable at each parcel's location\n",
    "    variable1[t,:,:] = np.reshape(interpolate.interpn((z,y,x), var1, coord, method = 'linear', bounds_error=False, fill_value= np.nan), (num_seeds_z, num_seeds_y))  \n",
    "    \n",
    "    #Timer\n",
    "    stop = time.time()\n",
    "    print(\"Integration {:01d} took {:.2f} seconds\".format(t, stop-start))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get variable data for final time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time_steps-1\n",
    "\n",
    "#Get get x, y, and z positions from scalar grid\n",
    "xloc = np.copy(xpos[t,:,:]-0.5).flatten()\n",
    "yloc = np.copy(ypos[t,:,:]-0.5).flatten()\n",
    "zloc = np.copy(zpos[t,:,:]-0.5).flatten()\n",
    "coord = []\n",
    "for i in range(len(xloc)):\n",
    "    coord.append((zloc[i], yloc[i], xloc[i])) \n",
    "\n",
    "#Variables\n",
    "variable1[t,:,:] = np.reshape(interpolate.interpn((z,y,x), var1, coord, method = 'linear', bounds_error=False, fill_value= np.nan), (num_seeds_z, num_seeds_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trajectory Data\n",
    "The x, y, and z positions and user-specified variable values are saved in 3D numpy arrays. The first dimension is time and the other two are the positions and values of variables of all the parcels at that specifc time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('trajectory_arrays/xpos', xpos)\n",
    "np.save('trajectory_arrays/ypos', ypos)\n",
    "np.save('trajectory_arrays/zpos', zpos_heightASL)\n",
    "np.save('trajectory_arrays/%s' %var_name1, variable1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
